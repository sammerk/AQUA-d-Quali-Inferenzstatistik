[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AQUA-d-Quali: Inferenzstatistik",
    "section": "",
    "text": "Übersicht",
    "crumbs": [
      "Übersicht"
    ]
  },
  {
    "objectID": "index.html#herzlich-willkommen-zur-sitzung-inferenzstatistik",
    "href": "index.html#herzlich-willkommen-zur-sitzung-inferenzstatistik",
    "title": "AQUA-d-Quali: Inferenzstatistik",
    "section": "Herzlich Willkommen zur Sitzung »Inferenzstatistik« 👋!",
    "text": "Herzlich Willkommen zur Sitzung »Inferenzstatistik« 👋!\nHeute wollen wir in die Welt der Inferenzstatistik eintauchen. Wie man in der Kapitelleiste links sehen kann werden dazu die folgenden Dinge behandeln bzw. üben:\n\nDie Unterscheidung von Inferenz- und Deskriptivstatistik in alltäglicher und wissenschaftlicher Sprache \np-Werte \n\nInterpretation\nDo’s and don’ts\n\nBayes Factors \n\nInterpretation\nDo’s and don’ts\n\n\nKonfidenzintervalle \n\nInterpretation\nDo’s and don’ts\n\nHighest Density Posterior Intervals \n\nInterpretation\nDo’s and don’ts",
    "crumbs": [
      "Übersicht"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#übung",
    "href": "Inferenz_versus_Deskriptivstatistik.html#übung",
    "title": "1  Inferenz- versus Deskriptivstatistik",
    "section": "1.1 Übung",
    "text": "1.1 Übung\nIm folgenden findet ihr leicht abgeänderte Pressemitteilungen und sollt entscheiden ob in dieser eine Inferenz- oder Deskriptivstatistik präsentiert wird.\n\nSteigerung der Motivation\n\n»Die Präsentation von Interviewausschnitten zeigte einen signifikanten Effekt auf die Wertschätzung des Faches Mathematik.«\n\nHier wird eine DeskriptivstatistikInferenzstatistik präsentiert\n\n\nFaktenboxen und Risikowahrnehmung\n\n»Wenn man annimmt, dass die Faktenboxen die Korrektheit der Risikoeinschätzung steigern, sind die erhobenen Daten mindestens 20fach wahrscheinlicher, als wenn man annimmt, dass die Korrektheit der Risikoeinschätzung gleichbleibt.«\n\nHier wird eine DeskriptivstatistikInferenzstatistik präsentiert\n\n\nActive Retrieval\n\n»Das aktive Wiederaufrufen von Infromationen via gefaltetem Tandembogen, war dem wiederholten Lesen des Bogen ergab ein Cohen’s d von \\(d\\) =.2. Dabei ist Cohen’s \\(d\\) als Differenz der zwei Gruppenmittelwerte geteilt durch die gemittelte Standardabweichung definiert.«\n\n\n\nMathematikkompetenz\n\n»Die erhobenen Daten sind unter der Annahme gleicher Mathematikkompetenzen von deutschen Schülerinnen und Schülern und dem OECD-Durchschnitt sehr unwahrscheinlich.«\n\nHier wird eine DeskriptivstatistikInferenzstatistik präsentiert\n\n\nStandzeiten von Untertiteln\n\n»Nach der Betrachtung von gekürzten Untertiteln mit längeren Standzeiten zeigten 58% der Kinder ein Verständnis über dem durchschnittlichen Verständnis von Sendungen mit konventionellen Untertiteln.«\n\nHier wird eine DeskriptivstatistikInferenzstatistik präsentiert",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#inferenz--und-deskriptivstatistik",
    "href": "Inferenz_versus_Deskriptivstatistik.html#inferenz--und-deskriptivstatistik",
    "title": "1  Inferenz- versus Deskriptivstatistik",
    "section": "1.2 Inferenz- und Deskriptivstatistik",
    "text": "1.2 Inferenz- und Deskriptivstatistik\n\n\nDeskriptivstatistiken machen Aussagen über vorliegende Datensätze z.B. »Median aller Noten eines Zeugnisses«\n\n\n\nInferenzstatistiken machen anhand von Daten Aussagen über (hypothetische) Mechanismen, die diese Daten erzeugen (Eid, Gollwitzer, & Schmitt, 2013) z.B. »Befürworten von 100 zufällig ausgewählten Erwachsenen 63 Ziffernnoten in der Grundschule, wie sicher liegt dann eine Zustimmung (&gt; 50%) in der Gesamterwachsenenbevölkerung vor?«",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#schätzung-vs.-testung",
    "href": "Inferenz_versus_Deskriptivstatistik.html#schätzung-vs.-testung",
    "title": "1  Inferenz- versus Deskriptivstatistik",
    "section": "1.3 Schätzung vs. Testung",
    "text": "1.3 Schätzung vs. Testung\n\n\n\n\n\n\n\n\n\nFrequentistischeStatistik\nBayesianischeStatistik\n\n\n\n\nParameterschätzung\nKonfidenzintervalle\nPosterior Distributions\n\n\nHypothesentest\np-Werte\nBayes Faktoren\n\n\n\n\nInferenzstatistische Schätzung (estimation with quantified uncertainty) trifft anhand von Stichproben Aussagen über Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.  (Inferenzstatistische) Hypothesentests bewerten anhand von Stichprobendaten die Gültigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde (John K. Kruschke & Liddell, 2018).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#hypothesenarten",
    "href": "Inferenz_versus_Deskriptivstatistik.html#hypothesenarten",
    "title": "1  Inferenz- versus Deskriptivstatistik",
    "section": "1.4 Hypothesenarten",
    "text": "1.4 Hypothesenarten\nBayesianische wie frequentistische Hypothesentests können unterschiedliche Arten von Hypothesen zugrunde gelegt werden:\n\nPunkthypothesen setzen Parameter gleich einer reellen Zahl; etwa \\(H_0\\text{: } \\delta = 0\\)\nÄquivalenzhypothesen nehmen Parameter in einem reellen Intervall an; etwa \\(H_0\\text{: } \\delta \\not\\in\\ [-.3, .3]\\)\nInformative Hypothesen nehmen eine Ordnungsrelation mehrerer Parameter an; etwa \\(\\mu_{\\text{Baseline}} &lt; \\mu_{\\text{Imaginary Pill}} &lt; \\mu_{\\text{Blinded Placebo}}\\)\n\n\nDie Art der (falsifiszierten) Hypothese entscheidet wesentlich stärker über den Informationsgehalt eines Hypothesentests als die Entscheidung für das frequentistische oder bayesianische Paradigma (Hoijtink, 2012).\n\nDies ist am leichtest anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese \\(H_0\\text{: } \\delta = 0\\) verworfen, wird entsprechend die Alternativhypothese \\(H_A\\text{: } \\delta \\neq 0\\) angenommen. Diese enthält aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 …) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enthält, umso leichter sie verworfen werden kann (Döring & Bortz, 2016).\nÄquivalenzhypothesen können sowohl frequentistisch (z.B. TOAST-Prozedur in  und JASP, Lakens, 2017) wie bayesianisch (z.B. ROPE-Ansatz John K. Kruschke, 2015) getestet werden. Für das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und  vor (z.B. {bain}, Gu, Hoijtink, Mulder, & Rosseel, 2019).\n\n\n\n\nDöring, N., & Bortz, J. (2016). Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften (5., vollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik Und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain: A Program for Bayesian Testing of Order Constrained Hypotheses in Structural Equation Models. Journal of Statistical Computation and Simulation, 89(8), 1526–1553.\n\n\nHoijtink, H. (2012). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton: CRC.\n\n\nKruschke, John K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nKruschke, John K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis Testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective. Psychonomic Bulletin & Review, 25, 178–206.\n\n\nLakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355–362.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "p-Werte.html#übung",
    "href": "p-Werte.html#übung",
    "title": "2  p-Werte",
    "section": "2.1 Übung",
    "text": "2.1 Übung\n\nWelche der folgenden Aussagen zu p-Werten sind korrekt (siehe Goodman, 2008)?\nIf p = .05, the null hypothesis has only a 5% chance of being true.\n\n true false\n\nA nonsignificant difference (eg, p &gt;.05) means there is no difference between groups.\n\n true false\n\nA statistically significant finding is clinically important.\n\n true false\n\nStudies with p-values on opposite sides of .05 are conflicting.\n\n true false\n\nStudies with the same p-value provide the same evidence against the null hypothesis.\n\n true false\n\np = .05 means that we have observed data that would occur only 5% of the time under the null hypothesis.\n\n true false\n\np = .05 means that if you reject the null hypothesis, the probability of a type I error is only 5%.\n\n true false\n\nWith a p = .05 threshold for significance, the chance of a type I error will be 5%.\n\n true false",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>p-Werte</span>"
    ]
  },
  {
    "objectID": "p-Werte.html#interpretation",
    "href": "p-Werte.html#interpretation",
    "title": "2  p-Werte",
    "section": "2.2 Interpretation",
    "text": "2.2 Interpretation\n\n2.2.1 Definition nach Kruschke (Kruschke, 2015)\n\nFormally, a \\(p\\) value can be defined as follows. For a set of actual data, let \\(T\\left(D_{\\text {actual }}\\right)\\) be a descriptive summary value of the data, such as a \\(t\\) statistic. Suppose that the actual data were sampled according to certain stopping and testing intentions denoted \\(I\\). Then the \\(p\\) value is defined as \\[\np \\text { value } \\equiv p\\left(T\\left(D_{\\text {simulated }}\\right) \\succeq T\\left(D_{\\text {actual }}\\right) \\mid \\mu, I\\right)\n\\] where \\(T\\left(D_{\\text {simulated }}\\right)\\) are the descriptive summaries of simulated data sampled from a hypothetical population characterized by parameter value \\(\\mu\\) according to the same stopping and testing intentions, \\(I\\), as the actual data. \\(\\succeq\\) means »is at least as extreme as, relative to the expected value of \\(T\\left(D_{\\text {simulated }}\\right)\\)«.\n\n\n\n2.2.2 Visualisierung\n#| standalone: true\n#| viewerHeight: 757\nlibrary(bslib)\nlibrary(bsicons)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h4(\"\"),\n layout_column_wrap(\n    width = \"100px\",\n    card(\n      sliderInput(\"d\", \"Cohen's 𝛅 (Population)\", min = 0, max = 3, value = 0.4, step = 0.1),\n      sliderInput(\"n\", \"Gruppengröße\", min = 2, max = 100, value = 20)\n      ),\n    value_box(\n      theme = value_box_theme(bg = \"#1bbc9d\", fg = \"#ffffff\"),\n      title = \"p-Wert\",\n      value = textOutput(\"pvaluetext\"),\n      showcase = bs_icon(\"speedometer\"),\n      p(\"Basierend auf der unten vorliegenden Stichprobe\"),\n      p(\"Bzgl. H₀: 𝛅 = 0\")\n  )),\n  card(\n    card_title(\"Stichprobe\"),\n    card_body(plotOutput(\"stripchart\"))\n    )\n)\n\n\n# Server\nserver &lt;- function(input, output, session) {\n  \n    df &lt;- reactive({\n      data.frame(Gruppe1 = rnorm(input$n), \n                 Gruppe2 = rnorm(input$n, input$d, 1)\n      )\n      })\n  \n  output$stripchart &lt;- renderPlot({\n\n    df_long &lt;- reshape(\n      data = df(),\n      varying = list(names(df())[1:2]),  # Columns to be melted\n      v.names = \"Value\",                      # Name of the variable column in the long format\n      timevar = \"Variable\",                   # Name of the column containing variable names\n      times = c(\"Gruppe 1\", \"Gruppe 2\"),      # New variable names in long format\n      direction = \"long\"                      # Pivoting from wide to long\n    )\n    \n    stripchart(Value ~ Variable, data = df_long,\n               pch = 19, frame = FALSE, \n               vertical = FALSE,\n               method = \"jitter\")\n  })\n  \n  output$pvaluetext &lt;- renderText({\n    t_test &lt;- t.test(df()$Gruppe1, df()$Gruppe2)\n    return(round(t_test$p.value, digits = 3))\n  })\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\n2.2.3 Don’ts\n\nNicht-signifikante p-Werte liefern keine Evidenz für die Nullhypothese, denn nicht-signifikante p-Werte sind inkonklusiv.\np-Werte können nicht als graduelle Evidenz interpretiert werden\n\nDemnach gibt es kein »höchstsignifikant«, »marginally significant«, etc.\n\np-Werte sind nur interpretierbar, wenn die Testintention und Stopping Rule bekannt und konstant sind\n\nAlso keinesfalls Daten erheben, sehen, dass der p-Wert knapp über dem \\(\\alpha\\)-Niveau liegt und daher weitere Daten erheben\n\np-Wert, \\(\\alpha\\)-Niveau, Effektstärke und Stichprobengröße sind deterministisch voneinander abhängig. Post hoc (also nach der Datenerhebung) anhand des vorgefundenen Effekts die Power zu berechnen ist also sinnfrei. Sie wird bei niedrigen p-Werten immer hoch und bei hohen p-Werten immer niedrig sein.\n\n\n\n2.2.4 Dos\n\nKeep in mind: Bei einfachen Testszenarien (z.B. t-Test) sind die p-Werte uniform verteilt, angenommen \\(H_0\\) ist wahr.\nVor der Datenerhebung festlegen, welche p-Werte berechnet werden und wie bei wechem Ergebnis weiterverfahren wird.  \nPlanung\n\n\n\n\n\nGoodman, S. (2008). A Dirty Dozen: Twelve p-Value Misconceptions. Seminars in Hematology, 45(3), 135–140.\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>p-Werte</span>"
    ]
  },
  {
    "objectID": "Bayes Factors.html#übung",
    "href": "Bayes Factors.html#übung",
    "title": "3  Bayes Factors",
    "section": "3.1 Übung",
    "text": "3.1 Übung\n\nWelche der folgenden Aussagen zu Bayes Factoren sind korrekt (siehe Wong, Kiers, & Tendeiro, 2022)?\nA group of researchers conducted an experiment in which three newly developed drugs for a deadly virus have been compared to a control group. The dependent variable is the recovery rate, the null hypothesis posits that the drug does not influence the recovery rate while the alternative hypothesis posits the drug does influence the recovery rate. After the experiment, two-sided Bayesian t-tests with a default prior were conducted. For drug A, it was found that BF10 is 2 while for drug B BF10 of 20 was found. For drug C, BF10 of 0.1 was found.  The probability of Drug A having an effect is one-tenth of that for drug B.\n\n true false\n\nFor Drug B, the probability of obtaining the observed data is 20 times higher under the alternative than under the null.\n\n true false\n\nThe alternative hypothesis (drug B has an effect) is 20 times more probable than the null hypothesis (drug B has no effect).\n\n true false\n\nDrug B demonstrated a positive effect on the recovery rate.\n\n true false\n\nThere is evidence suggesting that drug A demonstrated an effect on the recovery rate relative to the null hypothesis (there is no effect).\n\n true false\n\nFor drug C, there is evidence in favor of the null hypothesis (there is no effect).\n\n true false\n\nFor drug B, the Bayes factor disproved the null hypothesis (there is no effect).\n\n true false\n\nThe effect of drug B is bigger than the effect of drug A.\n\n true false\n\nThe strength of drug B affecting recovery rate cannot be known with the given information.\n\n true false\n\nIf the same group of researchers will conduct the same experiment repeatedly, they can be expected to find the presence of the effect from drug B in 20 out of 21 times.\n\n true false\n\nBased on the given Bayes Factor for drug A, drug A demonstrated no effect since the Bayes Factor is smaller than 3.\n\n true false",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes Factors</span>"
    ]
  },
  {
    "objectID": "Bayes Factors.html#interpretation",
    "href": "Bayes Factors.html#interpretation",
    "title": "3  Bayes Factors",
    "section": "3.2 Interpretation",
    "text": "3.2 Interpretation\n\n3.2.1 Definition nach Kruschke (Kruschke, 2015)\n\nFormally, a \\(p\\) value can be defined as follows. For a set of actual data, let \\(T\\left(D_{\\text {actual }}\\right)\\) be a descriptive summary value of the data, such as a \\(t\\) statistic. Suppose that the actual data were sampled according to certain stopping and testing intentions denoted \\(I\\). Then the \\(p\\) value is defined as \\[\np \\text { value } \\equiv p\\left(T\\left(D_{\\text {simulated }}\\right) \\succeq T\\left(D_{\\text {actual }}\\right) \\mid \\mu, I\\right)\n\\] where \\(T\\left(D_{\\text {simulated }}\\right)\\) are the descriptive summaries of simulated data sampled from a hypothetical population characterized by parameter value \\(\\mu\\) according to the same stopping and testing intentions, \\(I\\), as the actual data. \\(\\succeq\\) means »is at least as extreme as, relative to the expected value of \\(T\\left(D_{\\text {simulated }}\\right)\\)«.\n\n\n\n3.2.2 Visualisierung\n#| standalone: true\n#| viewerHeight: 757\nlibrary(bslib)\nlibrary(bsicons)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h4(\"\"),\n layout_column_wrap(\n    width = \"100px\",\n    card(\n      sliderInput(\"d\", \"Cohen's 𝛅 (Population)\", min = 0, max = 3, value = 0, step = 0.1),\n      sliderInput(\"n\", \"Gruppengröße\", min = 2, max = 500, value = 20)\n      ),\n    value_box(\n      theme = value_box_theme(bg = \"#1bbc9d\", fg = \"#ffffff\"),\n      title = \"BF₁₀:\",\n      value = textOutput(\"pvaluetext\"),\n      showcase = bs_icon(\"speedometer\"),\n      p(\"Basierend auf der unten vorliegenden Stichprobe\"),\n      p(\"Bzgl. H₀: 𝛅 = 0 & H₁: 𝛅 ≠ 0\")\n  )),\n  card(\n    card_title(\"Stichprobe\"),\n    card_body(plotOutput(\"stripchart\"))\n    )\n)\n\n\n# Server\nserver &lt;- function(input, output, session) {\n  \n    df &lt;- reactive({\n      data.frame(Gruppe1 = rnorm(input$n), \n                 Gruppe2 = rnorm(input$n, input$d, 1)\n      )\n      })\n  \n  output$stripchart &lt;- renderPlot({\n\n    df_long &lt;- reshape(\n      data = df(),\n      varying = list(names(df())[1:2]),  # Columns to be melted\n      v.names = \"Value\",                      # Name of the variable column in the long format\n      timevar = \"Variable\",                   # Name of the column containing variable names\n      times = c(\"Gruppe 1\", \"Gruppe 2\"),      # New variable names in long format\n      direction = \"long\"                      # Pivoting from wide to long\n    )\n    \n    stripchart(Value ~ Variable, data = df_long,\n               pch = 19, frame = FALSE, \n               vertical = FALSE,\n               method = \"jitter\")\n  })\n  \n  output$pvaluetext &lt;- renderText({\n    t_test &lt;- t.test(df()$Gruppe1, df()$Gruppe2)\n    bf &lt;- ifelse(t_test$p.value &lt;= .1, \n                 3*sqrt(input$n)*t_test$p.value,\n                 ifelse(t_test$p.value &lt;= .5, \n                 4/3*sqrt(input$n)*(t_test$p.value)^(2/3),\n                 sqrt(input$n)*(t_test$p.value)^(1/4)\n                 )\n          )\n    \n                 \n                 \n     return(round(1/bf, digits = 3))\n  })\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n3.2.3 Don’ts\n\nBF liefern keine relative Evidenz für Hypothesen, sondern für Daten\nBF liefern keine Evidenz für Daten, sondern relative Evidenz\nBF sind Prior-sensitiv. Diese müssen also berichtet werden\n\n\n\n3.2.4 Dos\n\nOptional Stopping ist kein Problem im bayesianischen Paradigma (Rouder, 2014). Wer also keinen Plan von der zu erwartenden Effektstärke hat und demnach auch keine Poweranalyse machen kann, kann schlicht »ins Blaue« erheben, immer wieder BF berechnen und entscheiden ob weitererhoben wird.\nBFs können aus p-Werten via der folgenden Daumenregeln (Wagenmakers, 2022) approximiert werden: \\[\\mathrm{approxBF}_{01} \\approx \\begin{cases}3 p \\sqrt{n} & \\text { if } p \\leq .10 \\\\ \\sqrt{p} \\sqrt{n} & \\text { if } .10&lt;p \\leq .50 \\text { (leichter zu merken) } \\\\ \\frac{4}{3} p^{2 / 3} \\sqrt{n} & \\text { if } .10&lt;p \\leq .50 \\text { (präziser) } \\\\ p^{1 / 4} \\sqrt{n} & \\text { if } p&gt;.50\\end{cases}\\]\n\n\n\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nRouder, J. N. (2014). Optional Stopping: No Problem for Bayesians. Psychonomic Bulletin & Review, 21(2), 301–308.\n\n\nWagenmakers, E.-J. (2022). Approximate Objective Bayes Factors from P-Values and Sample Size: The 3p\\(\\surd\\)n Rule (Preprint). PsyArXiv.\n\n\nWong, T. K., Kiers, H., & Tendeiro, J. (2022). On the Potential Mismatch Between the Function of the Bayes Factor and Researchers’ Expectations. Collabra: Psychology, 8(1), 36357.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes Factors</span>"
    ]
  },
  {
    "objectID": "Konfidenzintervalle.html#interpretation-nach-effectsizeguide",
    "href": "Konfidenzintervalle.html#interpretation-nach-effectsizeguide",
    "title": "4  Konfidenzintervalle",
    "section": "4.1 Interpretation nach Jané u. a. (2024)",
    "text": "4.1 Interpretation nach Jané u. a. (2024)\n\n»What is the correct interpretation of a confidence interval? Imagine you conducted a study where you compared two groups. You obtained a Cohen’s = 0.3, 95% CI [0.2, 0.4]. How do you interpret this confidence interval? Confidence intervals are yielded by a certain procedure, such that when the procedure is repeatedly applied to a series of hypothetical datasets drawn from the studied population/populations, it yields intervals that contain the true parameter value (in our example, it means the true difference between the two groups) in 95% of the cases. For the effect estimate and confidence intervals to be valid, the data and test must meet the assumptions of the estimating procedure. In colloquial terms, if we conduct this research over and over (repeating the same sampling procedure, administering the same experimental manipulation, conducting the same statistical analysis, etc.), because of sampling variability (our samples are slightly different at each time), we will get different Cohen’s values. For each of these values, we calculate a 95% interval. Then, among all these many intervals, we expect that 95% of them will contain the true, which we never know exactly.«\n\nDiese Interpretation wird sehr gut durch diese interaktive Visualisierung  veranschaulicht.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Konfidenzintervalle</span>"
    ]
  },
  {
    "objectID": "Konfidenzintervalle.html#donts",
    "href": "Konfidenzintervalle.html#donts",
    "title": "4  Konfidenzintervalle",
    "section": "4.2 Don’ts",
    "text": "4.2 Don’ts\n\np-Werte und Konfidenzintervalle drücken dieselbe Information in unterschiedlichen Metriken aus. Da p-Werte keine Evidenz für die Nullhypothese liefern können, können CI dies auch nicht.\nDie Interpretation von CI »als das Intervall, das den wahren Wert mit 95%-Wahrscheinlichkeit enthält« ist falsch bzw. mindestens hochproblematisch.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Konfidenzintervalle</span>"
    ]
  },
  {
    "objectID": "Konfidenzintervalle.html#dos",
    "href": "Konfidenzintervalle.html#dos",
    "title": "4  Konfidenzintervalle",
    "section": "4.3 Dos",
    "text": "4.3 Dos\n\nWer frequentistische Inferenzstatistik betreibt verliert nichts und gewinnt nur, wenn zusätzlich zum p-Wert Ci angegeben werden. Go for it 💨.\n\n\n\n\n\nJané, M. B., Xiao, Q., Yeung, S. K., Ben-Shachar, M. S., Caldwell, A. R., Cousineau, D., … Feldman, G. (2024). Guide to Effect Sizes and Confidence Intervals.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Konfidenzintervalle</span>"
    ]
  },
  {
    "objectID": "Highest Density Posterior Intervals.html#interaktive-visualisierung",
    "href": "Highest Density Posterior Intervals.html#interaktive-visualisierung",
    "title": "5  Highest Density Posterior Intervals",
    "section": "5.1 Interaktive Visualisierung",
    "text": "5.1 Interaktive Visualisierung\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Prior\"),\n         card_body(\n           sliderInput(\n             \"prior_mu\",\n             \"Prior Mean\",\n             min = 0,\n             max = 1,\n             value = .5,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi\",\n             \"Prior Precision\",\n             min = 2,\n             max = 100,\n             value = 3,\n             step = 1\n           )\n         )),\n    card(card_header(class = \"bg-dark\", \"Data\"),\n         card_body(\n           numericInput(\n             \"successes\",\n             \"Zustimmung G9\",\n             min = 0,\n             value = 13,\n             step = 1\n           ),\n           numericInput(\n             \"failures\",\n             \"Ablehnung G9\",\n             min = 0,\n             value = 8,\n             step = 1\n           )\n         ))), \n  card(card_header(\"Posterior\", class = \"bg-dark\"),\n       card_body(plotOutput(\"plot\")))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes &lt;- reactive({\n  muphi_to_shapes(input$prior_mu, input$prior_phi)\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n  \n  # set x-axis\n  p &lt;- seq(0,1, length=1000)\n  \n  # compute max-desity for ylim and legend position\n  density_max &lt;-\n    max(c(\n      dbeta(p,\n            prior_shapes()$shape1,\n            prior_shapes()$shape2),\n      dbeta(\n        p,\n        prior_shapes()$shape1 + input$successes,\n        prior_shapes()$shape2 + input$failures\n      )\n    ))\n  \n  # compute lower bound of 96%-HPDI\n  hpdi_lb &lt;-\n    qbeta(.02,\n           prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  # compute upper bound of 96%-HPDI\n  hpdi_ub &lt;-\n    qbeta(.98,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  \n  # create plot\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes()$shape1,\n          prior_shapes()$shape2),\n    type = 'l',\n    col = \"#1bbc9d\",\n    ylab = \"Wahrscheinlichkeitsdichte\",\n    xlab = \"Anteil G9-Befürworter:innen\",\n    frame.plot = F,\n    ylim = c(0, density_max)\n    )\n  lines(p,\n        dbeta(\n          p,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures\n          ),\n          col = '#EA80FC'\n        )\n  polygon(c(hpdi_lb, hpdi_lb, hpdi_ub, hpdi_ub),\n          c(0, density_max/40, density_max/40, 0),\n          col = \"#EA80FC30\",\n          border = \"#EA80FC00\")\n  legend(\n    bty = \"n\",\n    .8,\n    density_max,\n    c('Prior', 'Posterior', '96% HPDI'),\n    lty = c(1, 1, 1),\n    lwd = c(1, 1, 8),\n    col = c('#1bbc9d', '#EA80FC', '#EA80FC30')\n  )\n\n})\n\n### debug ######################################################################\n# output$debug &lt;- renderPrint({\n#   max(c(\n#                dbeta(p, \n#                      prior_shapes()$shape1, \n#                      prior_shapes()$shape2),\n#                dbeta(p, \n#                      prior_shapes()$shape1 + input$successes, \n#                      prior_shapes()$shape2 + input$failures))\n#              )\n#              \n# })\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Highest Density Posterior Intervals</span>"
    ]
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "Literatur",
    "section": "",
    "text": "Döring, N., & Bortz, J. (2016). Forschungsmethoden und\nEvaluation in den Sozial- und Humanwissenschaften (5.,\nvollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und\nForschungsmethoden: Lehrbuch. Mit\nOnline-Materialien (3rd ed.). Beltz.\n\n\nGoodman, S. (2008). A dirty dozen:\nTwelve p-value misconceptions. Seminars in\nHematology, 45(3), 135–140.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain:\nA program for Bayesian testing of order\nconstrained hypotheses in structural equation models. Journal of\nStatistical Computation and Simulation, 89(8), 1526–1553.\n\n\nHoijtink, H. (2012). Informative hypotheses: Theory and\npractice for behavioral and social scientists. Boca\nRaton: CRC.\n\n\nJané, M. B., Xiao, Q., Yeung, S. K., Ben-Shachar, M. S., Caldwell, A.\nR., Cousineau, D., … Feldman, G. (2024). Guide to effect sizes and\nconfidence intervals.\n\n\nKruschke, John K. (2015). Doing Bayesian data analysis:\nA tutorial with R, JAGS, and\nStan (2nd ed.). Academic Press.\n\n\nKruschke, John K., & Liddell, T. M. (2018). The\nBayesian new statistics: Hypothesis testing,\nestimation, meta-analysis, and power analysis from a\nBayesian perspective. Psychonomic Bulletin &\nReview, 25, 178–206.\n\n\nLakens, D. (2017). Equivalence\nTests: A Practical Primer for t\nTests, Correlations, and\nMeta-Analyses. Social Psychological and Personality\nScience, 8(4), 355–362.\n\n\nRouder, J. N. (2014). Optional stopping:\nNo problem for Bayesians. Psychonomic\nBulletin & Review, 21(2), 301–308.\n\n\nWagenmakers, E.-J. (2022). Approximate objective\nBayes Factors from p-values and sample size:\nThe 3p$\\surd$n rule (Preprint).\nPsyArXiv.\n\n\nWong, T. K., Kiers, H., & Tendeiro, J. (2022). On the Potential\nMismatch Between the Function of the Bayes\nFactor and Researchers’\nExpectations. Collabra: Psychology,\n8(1), 36357.",
    "crumbs": [
      "Literatur"
    ]
  }
]