[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AQUA-d-Quali: Inferenzstatistik",
    "section": "",
    "text": "√úbersicht",
    "crumbs": [
      "√úbersicht"
    ]
  },
  {
    "objectID": "index.html#herzlich-willkommen-zur-sitzung-inferenzstatistik",
    "href": "index.html#herzlich-willkommen-zur-sitzung-inferenzstatistik",
    "title": "AQUA-d-Quali: Inferenzstatistik",
    "section": "Herzlich Willkommen zur Sitzung ¬ªInferenzstatistik¬´ üëã!",
    "text": "Herzlich Willkommen zur Sitzung ¬ªInferenzstatistik¬´ üëã!\nHeute wollen wir in die Welt der Inferenzstatistik eintauchen. Wie man in der Kapitelleiste links sehen kann werden dazu die folgenden Dinge behandeln bzw. √ºben:\n\nDie Unterscheidung von Inferenz- und Deskriptivstatistik in allt√§glicher und wissenschaftlicher Sprache \np-Werte \n\nInterpretation\nDo‚Äôs and don‚Äôts\n\nBayes Factors \n\nInterpretation\nDo‚Äôs and don‚Äôts\n\n\nKonfidenzintervalle \n\nInterpretation\nDo‚Äôs and don‚Äôts\n\nHighest Density Posterior Intervals \n\nInterpretation\nDo‚Äôs and don‚Äôts",
    "crumbs": [
      "√úbersicht"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#√ºbung",
    "href": "Inferenz_versus_Deskriptivstatistik.html#√ºbung",
    "title": "1¬† Inferenz- versus Deskriptivstatistik",
    "section": "1.1 √úbung",
    "text": "1.1 √úbung\nIm folgenden findet ihr leicht abge√§nderte Pressemitteilungen und sollt entscheiden ob in dieser eine Inferenz- oder Deskriptivstatistik pr√§sentiert wird.\n\nSteigerung der Motivation\n\n¬ªDie Pr√§sentation von Interviewausschnitten zeigte einen signifikanten Effekt auf die Wertsch√§tzung des Faches Mathematik.¬´\n\nHier wird eine DeskriptivstatistikInferenzstatistik pr√§sentiert\n\n\nFaktenboxen und Risikowahrnehmung\n\n¬ªWenn man annimmt, dass die Faktenboxen die Korrektheit der Risikoeinsch√§tzung steigern, sind die erhobenen Daten mindestens 20fach wahrscheinlicher, als wenn man annimmt, dass die Korrektheit der Risikoeinsch√§tzung gleichbleibt.¬´\n\nHier wird eine DeskriptivstatistikInferenzstatistik pr√§sentiert\n\n\nActive Retrieval\n\n¬ªDas aktive Wiederaufrufen von Infromationen via gefaltetem Tandembogen, war dem wiederholten Lesen des Bogen ergab ein Cohen‚Äôs d von \\(d\\) =.2. Dabei ist Cohen‚Äôs \\(d\\) als Differenz der zwei Gruppenmittelwerte geteilt durch die gemittelte Standardabweichung definiert.¬´\n\n\n\nMathematikkompetenz\n\n¬ªDie erhobenen Daten sind unter der Annahme gleicher Mathematikkompetenzen von deutschen Sch√ºlerinnen und Sch√ºlern und dem OECD-Durchschnitt sehr unwahrscheinlich.¬´\n\nHier wird eine DeskriptivstatistikInferenzstatistik pr√§sentiert\n\n\nStandzeiten von Untertiteln\n\n¬ªNach der Betrachtung von gek√ºrzten Untertiteln mit l√§ngeren Standzeiten zeigten 58% der Kinder ein Verst√§ndnis √ºber dem durchschnittlichen Verst√§ndnis von Sendungen mit konventionellen Untertiteln.¬´\n\nHier wird eine DeskriptivstatistikInferenzstatistik pr√§sentiert",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#inferenz--und-deskriptivstatistik",
    "href": "Inferenz_versus_Deskriptivstatistik.html#inferenz--und-deskriptivstatistik",
    "title": "1¬† Inferenz- versus Deskriptivstatistik",
    "section": "1.2 Inferenz- und Deskriptivstatistik",
    "text": "1.2 Inferenz- und Deskriptivstatistik\n\n\nDeskriptivstatistiken machen Aussagen √ºber vorliegende Datens√§tze z.B. ¬ªMedian aller Noten eines Zeugnisses¬´\n\n\n\nInferenzstatistiken machen anhand von Daten Aussagen √ºber (hypothetische) Mechanismen, die diese Daten erzeugen (Eid, Gollwitzer, & Schmitt, 2013) z.B. ¬ªBef√ºrworten von 100 zuf√§llig ausgew√§hlten Erwachsenen 63 Ziffernnoten in der Grundschule, wie sicher liegt dann eine Zustimmung (&gt; 50%) in der Gesamterwachsenenbev√∂lkerung vor?¬´",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#sch√§tzung-vs.-testung",
    "href": "Inferenz_versus_Deskriptivstatistik.html#sch√§tzung-vs.-testung",
    "title": "1¬† Inferenz- versus Deskriptivstatistik",
    "section": "1.3 Sch√§tzung vs.¬†Testung",
    "text": "1.3 Sch√§tzung vs.¬†Testung\n\n\n\n\n\n\n\n\n\nFrequentistischeStatistik\nBayesianischeStatistik\n\n\n\n\nParametersch√§tzung\nKonfidenzintervalle\nPosterior Distributions\n\n\nHypothesentest\np-Werte\nBayes Faktoren\n\n\n\n\nInferenzstatistische Sch√§tzung (estimation with quantified uncertainty) trifft anhand von Stichproben Aussagen √ºber Parameter der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde.  (Inferenzstatistische) Hypothesentests bewerten anhand von Stichprobendaten die G√ºltigkeit von Hypothesen in der Grundgesamtheit (Population) aus der die Stichprobe gezogen wurde (John K. Kruschke & Liddell, 2018).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "Inferenz_versus_Deskriptivstatistik.html#hypothesenarten",
    "href": "Inferenz_versus_Deskriptivstatistik.html#hypothesenarten",
    "title": "1¬† Inferenz- versus Deskriptivstatistik",
    "section": "1.4 Hypothesenarten",
    "text": "1.4 Hypothesenarten\nBayesianische wie frequentistische Hypothesentests k√∂nnen unterschiedliche Arten von Hypothesen zugrunde gelegt werden:\n\nPunkthypothesen setzen Parameter gleich einer reellen Zahl; etwa \\(H_0\\text{: } \\delta = 0\\)\n√Ñquivalenzhypothesen nehmen Parameter in einem reellen Intervall an; etwa \\(H_0\\text{: } \\delta \\not\\in\\ [-.3, .3]\\)\nInformative Hypothesen nehmen eine Ordnungsrelation mehrerer Parameter an; etwa \\(\\mu_{\\text{Baseline}} &lt; \\mu_{\\text{Imaginary Pill}} &lt; \\mu_{\\text{Blinded Placebo}}\\)\n\n\nDie Art der (falsifiszierten) Hypothese entscheidet wesentlich st√§rker √ºber den Informationsgehalt eines Hypothesentests als die Entscheidung f√ºr das frequentistische oder bayesianische Paradigma (Hoijtink, 2012).\n\nDies ist am leichtest anhand der Nullhypothese nachvollziehbar. Wird etwa die Nullhypothese \\(H_0\\text{: } \\delta = 0\\) verworfen, wird entsprechend die Alternativhypothese \\(H_A\\text{: } \\delta \\neq 0\\) angenommen. Diese enth√§lt aber quasi keine Information, da sie nur mit einer einzigen Beobachtung (d = 0.000000 ‚Ä¶) verworfen werden kann und im kritischen Rationalismus gilt, dass eine Aussage umso mehr Information enth√§lt, umso leichter sie verworfen werden kann (D√∂ring & Bortz, 2016).\n√Ñquivalenzhypothesen k√∂nnen sowohl frequentistisch (z.B. TOAST-Prozedur in  und JASP, Lakens, 2017) wie bayesianisch (z.B. ROPE-Ansatz John K. Kruschke, 2015) getestet werden. F√ºr das Testen informativer Hypothesen liegen bayesianische Methoden in (u.a.) JASP und  vor (z.B. {bain}, Gu, Hoijtink, Mulder, & Rosseel, 2019).\n\n\n\n\nD√∂ring, N., & Bortz, J. (2016). Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften (5., vollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik Und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain: A Program for Bayesian Testing of Order Constrained Hypotheses in Structural Equation Models. Journal of Statistical Computation and Simulation, 89(8), 1526‚Äì1553.\n\n\nHoijtink, H. (2012). Informative Hypotheses: Theory and Practice for Behavioral and Social Scientists. Boca Raton: CRC.\n\n\nKruschke, John K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nKruschke, John K., & Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis Testing, Estimation, Meta-Analysis, and Power Analysis from a Bayesian Perspective. Psychonomic Bulletin & Review, 25, 178‚Äì206.\n\n\nLakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses. Social Psychological and Personality Science, 8(4), 355‚Äì362.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Inferenz- versus Deskriptivstatistik</span>"
    ]
  },
  {
    "objectID": "p-Werte.html#√ºbung",
    "href": "p-Werte.html#√ºbung",
    "title": "2¬† p-Werte",
    "section": "2.1 √úbung",
    "text": "2.1 √úbung\n\nWelche der folgenden Aussagen zu p-Werten sind korrekt (siehe Goodman, 2008)?\nIf p = .05, the null hypothesis has only a 5% chance of being true.\n\n true false\n\nA nonsignificant difference (eg, p &gt;.05) means there is no difference between groups.\n\n true false\n\nA statistically significant finding is clinically important.\n\n true false\n\nStudies with p-values on opposite sides of .05 are conflicting.\n\n true false\n\nStudies with the same p-value provide the same evidence against the null hypothesis.\n\n true false\n\np = .05 means that we have observed data that would occur only 5% of the time under the null hypothesis.\n\n true false\n\np = .05 means that if you reject the null hypothesis, the probability of a type I error is only 5%.\n\n true false\n\nWith a p = .05 threshold for significance, the chance of a type I error will be 5%.\n\n true false",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>p-Werte</span>"
    ]
  },
  {
    "objectID": "p-Werte.html#interpretation",
    "href": "p-Werte.html#interpretation",
    "title": "2¬† p-Werte",
    "section": "2.2 Interpretation",
    "text": "2.2 Interpretation\n\n2.2.1 Definition nach Kruschke (Kruschke, 2015)\n\nFormally, a \\(p\\) value can be defined as follows. For a set of actual data, let \\(T\\left(D_{\\text {actual }}\\right)\\) be a descriptive summary value of the data, such as a \\(t\\) statistic. Suppose that the actual data were sampled according to certain stopping and testing intentions denoted \\(I\\). Then the \\(p\\) value is defined as \\[\np \\text { value } \\equiv p\\left(T\\left(D_{\\text {simulated }}\\right) \\succeq T\\left(D_{\\text {actual }}\\right) \\mid \\mu, I\\right)\n\\] where \\(T\\left(D_{\\text {simulated }}\\right)\\) are the descriptive summaries of simulated data sampled from a hypothetical population characterized by parameter value \\(\\mu\\) according to the same stopping and testing intentions, \\(I\\), as the actual data. \\(\\succeq\\) means ¬ªis at least as extreme as, relative to the expected value of \\(T\\left(D_{\\text {simulated }}\\right)\\)¬´.\n\n\n\n2.2.2 Visualisierung\n#| standalone: true\n#| viewerHeight: 757\nlibrary(bslib)\nlibrary(bsicons)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h4(\"\"),\n layout_column_wrap(\n    width = \"100px\",\n    card(\n      sliderInput(\"d\", \"Cohen's ùõÖ (Population)\", min = 0, max = 3, value = 0.4, step = 0.1),\n      sliderInput(\"n\", \"Gruppengr√∂√üe\", min = 2, max = 100, value = 20)\n      ),\n    value_box(\n      theme = value_box_theme(bg = \"#1bbc9d\", fg = \"#ffffff\"),\n      title = \"p-Wert\",\n      value = textOutput(\"pvaluetext\"),\n      showcase = bs_icon(\"speedometer\"),\n      p(\"Basierend auf der unten vorliegenden Stichprobe\"),\n      p(\"Bzgl. H‚ÇÄ: ùõÖ = 0\")\n  )),\n  card(\n    card_title(\"Stichprobe\"),\n    card_body(plotOutput(\"stripchart\"))\n    )\n)\n\n\n# Server\nserver &lt;- function(input, output, session) {\n  \n    df &lt;- reactive({\n      data.frame(Gruppe1 = rnorm(input$n), \n                 Gruppe2 = rnorm(input$n, input$d, 1)\n      )\n      })\n  \n  output$stripchart &lt;- renderPlot({\n\n    df_long &lt;- reshape(\n      data = df(),\n      varying = list(names(df())[1:2]),  # Columns to be melted\n      v.names = \"Value\",                      # Name of the variable column in the long format\n      timevar = \"Variable\",                   # Name of the column containing variable names\n      times = c(\"Gruppe 1\", \"Gruppe 2\"),      # New variable names in long format\n      direction = \"long\"                      # Pivoting from wide to long\n    )\n    \n    stripchart(Value ~ Variable, data = df_long,\n               pch = 19, frame = FALSE, \n               vertical = FALSE,\n               method = \"jitter\")\n  })\n  \n  output$pvaluetext &lt;- renderText({\n    t_test &lt;- t.test(df()$Gruppe1, df()$Gruppe2)\n    return(round(t_test$p.value, digits = 3))\n  })\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\n2.2.3 Don‚Äôts\n\nNicht-signifikante p-Werte liefern keine Evidenz f√ºr die Nullhypothese, denn nicht-signifikante p-Werte sind inkonklusiv.\np-Werte k√∂nnen nicht als graduelle Evidenz interpretiert werden\n\nDemnach gibt es kein ¬ªh√∂chstsignifikant¬´, ¬ªmarginally significant¬´, etc.\n\np-Werte sind nur interpretierbar, wenn die Testintention und Stopping Rule bekannt und konstant sind\n\nAlso keinesfalls Daten erheben, sehen, dass der p-Wert knapp √ºber dem \\(\\alpha\\)-Niveau liegt und daher weitere Daten erheben\n\np-Wert, \\(\\alpha\\)-Niveau, Effektst√§rke und Stichprobengr√∂√üe sind deterministisch voneinander abh√§ngig. Post hoc (also nach der Datenerhebung) anhand des vorgefundenen Effekts die Power zu berechnen ist also sinnfrei. Sie wird bei niedrigen p-Werten immer hoch und bei hohen p-Werten immer niedrig sein.\n\n\n\n2.2.4 Dos\n\nKeep in mind: Bei einfachen Testszenarien (z.B. t-Test) sind die p-Werte uniform verteilt, angenommen \\(H_0\\) ist wahr.\nVor der Datenerhebung festlegen, welche p-Werte berechnet werden und wie bei wechem Ergebnis weiterverfahren wird.  \nPlanung\n\n\n\n\n\nGoodman, S. (2008). A Dirty Dozen: Twelve p-Value Misconceptions. Seminars in Hematology, 45(3), 135‚Äì140.\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>p-Werte</span>"
    ]
  },
  {
    "objectID": "Bayes Factors.html#√ºbung",
    "href": "Bayes Factors.html#√ºbung",
    "title": "3¬† Bayes Factors",
    "section": "3.1 √úbung",
    "text": "3.1 √úbung\n\nWelche der folgenden Aussagen zu Bayes Factoren sind korrekt (siehe Wong, Kiers, & Tendeiro, 2022)?\nA group of researchers conducted an experiment in which three newly developed drugs for a deadly virus have been compared to a control group. The dependent variable is the recovery rate, the null hypothesis posits that the drug does not influence the recovery rate while the alternative hypothesis posits the drug does influence the recovery rate. After the experiment, two-sided Bayesian t-tests with a default prior were conducted. For drug A, it was found that BF10 is 2 while for drug B BF10 of 20 was found. For drug C, BF10 of 0.1 was found.  The probability of Drug A having an effect is one-tenth of that for drug B.\n\n true false\n\nFor Drug B, the probability of obtaining the observed data is 20 times higher under the alternative than under the null.\n\n true false\n\nThe alternative hypothesis (drug B has an effect) is 20 times more probable than the null hypothesis (drug B has no effect).\n\n true false\n\nDrug B demonstrated a positive effect on the recovery rate.\n\n true false\n\nThere is evidence suggesting that drug A demonstrated an effect on the recovery rate relative to the null hypothesis (there is no effect).\n\n true false\n\nFor drug C, there is evidence in favor of the null hypothesis (there is no effect).\n\n true false\n\nFor drug B, the Bayes factor disproved the null hypothesis (there is no effect).\n\n true false\n\nThe effect of drug B is bigger than the effect of drug A.\n\n true false\n\nThe strength of drug B affecting recovery rate cannot be known with the given information.\n\n true false\n\nIf the same group of researchers will conduct the same experiment repeatedly, they can be expected to find the presence of the effect from drug B in 20 out of 21 times.\n\n true false\n\nBased on the given Bayes Factor for drug A, drug A demonstrated no effect since the Bayes Factor is smaller than 3.\n\n true false",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Bayes Factors</span>"
    ]
  },
  {
    "objectID": "Bayes Factors.html#interpretation",
    "href": "Bayes Factors.html#interpretation",
    "title": "3¬† Bayes Factors",
    "section": "3.2 Interpretation",
    "text": "3.2 Interpretation\n\n3.2.1 Definition nach Kruschke (Kruschke, 2015)\n\nFormally, a \\(p\\) value can be defined as follows. For a set of actual data, let \\(T\\left(D_{\\text {actual }}\\right)\\) be a descriptive summary value of the data, such as a \\(t\\) statistic. Suppose that the actual data were sampled according to certain stopping and testing intentions denoted \\(I\\). Then the \\(p\\) value is defined as \\[\np \\text { value } \\equiv p\\left(T\\left(D_{\\text {simulated }}\\right) \\succeq T\\left(D_{\\text {actual }}\\right) \\mid \\mu, I\\right)\n\\] where \\(T\\left(D_{\\text {simulated }}\\right)\\) are the descriptive summaries of simulated data sampled from a hypothetical population characterized by parameter value \\(\\mu\\) according to the same stopping and testing intentions, \\(I\\), as the actual data. \\(\\succeq\\) means ¬ªis at least as extreme as, relative to the expected value of \\(T\\left(D_{\\text {simulated }}\\right)\\)¬´.\n\n\n\n3.2.2 Visualisierung\n#| standalone: true\n#| viewerHeight: 757\nlibrary(bslib)\nlibrary(bsicons)\n\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h4(\"\"),\n layout_column_wrap(\n    width = \"100px\",\n    card(\n      sliderInput(\"d\", \"Cohen's ùõÖ (Population)\", min = 0, max = 3, value = 0, step = 0.1),\n      sliderInput(\"n\", \"Gruppengr√∂√üe\", min = 2, max = 500, value = 20)\n      ),\n    value_box(\n      theme = value_box_theme(bg = \"#1bbc9d\", fg = \"#ffffff\"),\n      title = \"BF‚ÇÅ‚ÇÄ:\",\n      value = textOutput(\"pvaluetext\"),\n      showcase = bs_icon(\"speedometer\"),\n      p(\"Basierend auf der unten vorliegenden Stichprobe\"),\n      p(\"Bzgl. H‚ÇÄ: ùõÖ = 0 & H‚ÇÅ: ùõÖ ‚â† 0\")\n  )),\n  card(\n    card_title(\"Stichprobe\"),\n    card_body(plotOutput(\"stripchart\"))\n    )\n)\n\n\n# Server\nserver &lt;- function(input, output, session) {\n  \n    df &lt;- reactive({\n      data.frame(Gruppe1 = rnorm(input$n), \n                 Gruppe2 = rnorm(input$n, input$d, 1)\n      )\n      })\n  \n  output$stripchart &lt;- renderPlot({\n\n    df_long &lt;- reshape(\n      data = df(),\n      varying = list(names(df())[1:2]),  # Columns to be melted\n      v.names = \"Value\",                      # Name of the variable column in the long format\n      timevar = \"Variable\",                   # Name of the column containing variable names\n      times = c(\"Gruppe 1\", \"Gruppe 2\"),      # New variable names in long format\n      direction = \"long\"                      # Pivoting from wide to long\n    )\n    \n    stripchart(Value ~ Variable, data = df_long,\n               pch = 19, frame = FALSE, \n               vertical = FALSE,\n               method = \"jitter\")\n  })\n  \n  output$pvaluetext &lt;- renderText({\n    t_test &lt;- t.test(df()$Gruppe1, df()$Gruppe2)\n    bf &lt;- ifelse(t_test$p.value &lt;= .1, \n                 3*sqrt(input$n)*t_test$p.value,\n                 ifelse(t_test$p.value &lt;= .5, \n                 4/3*sqrt(input$n)*(t_test$p.value)^(2/3),\n                 sqrt(input$n)*(t_test$p.value)^(1/4)\n                 )\n          )\n    \n                 \n                 \n     return(round(1/bf, digits = 3))\n  })\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n3.2.3 Don‚Äôts\n\nBF liefern keine relative Evidenz f√ºr Hypothesen, sondern f√ºr Daten\nBF liefern keine Evidenz f√ºr Daten, sondern relative Evidenz\nBF sind Prior-sensitiv. Diese m√ºssen also berichtet werden\n\n\n\n3.2.4 Dos\n\nOptional Stopping ist kein Problem im bayesianischen Paradigma (Rouder, 2014). Wer also keinen Plan von der zu erwartenden Effektst√§rke hat und demnach auch keine Poweranalyse machen kann, kann schlicht ¬ªins Blaue¬´ erheben, immer wieder BF berechnen und entscheiden ob weitererhoben wird.\nBFs k√∂nnen aus p-Werten via der folgenden Daumenregeln (Wagenmakers, 2022) approximiert werden: \\[\\mathrm{approxBF}_{01} \\approx \\begin{cases}3 p \\sqrt{n} & \\text { if } p \\leq .10 \\\\ \\sqrt{p} \\sqrt{n} & \\text { if } .10&lt;p \\leq .50 \\text { (leichter zu merken) } \\\\ \\frac{4}{3} p^{2 / 3} \\sqrt{n} & \\text { if } .10&lt;p \\leq .50 \\text { (pr√§ziser) } \\\\ p^{1 / 4} \\sqrt{n} & \\text { if } p&gt;.50\\end{cases}\\]\n\n\n\n\n\nKruschke, J. K. (2015). Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan (2nd Aufl.). Academic Press.\n\n\nRouder, J. N. (2014). Optional Stopping: No Problem for Bayesians. Psychonomic Bulletin & Review, 21(2), 301‚Äì308.\n\n\nWagenmakers, E.-J. (2022). Approximate Objective Bayes Factors from P-Values and Sample Size: The 3p\\(\\surd\\)n Rule (Preprint). PsyArXiv.\n\n\nWong, T. K., Kiers, H., & Tendeiro, J. (2022). On the Potential Mismatch Between the Function of the Bayes Factor and Researchers‚Äô Expectations. Collabra: Psychology, 8(1), 36357.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Bayes Factors</span>"
    ]
  },
  {
    "objectID": "Konfidenzintervalle.html#interpretation-nach-effectsizeguide",
    "href": "Konfidenzintervalle.html#interpretation-nach-effectsizeguide",
    "title": "4¬† Konfidenzintervalle",
    "section": "4.1 Interpretation nach Jan√© u.¬†a. (2024)",
    "text": "4.1 Interpretation nach Jan√© u.¬†a. (2024)\n\n¬ªWhat is the correct interpretation of a confidence interval? Imagine you conducted a study where you compared two groups. You obtained a Cohen‚Äôs = 0.3, 95% CI [0.2, 0.4]. How do you interpret this confidence interval? Confidence intervals are yielded by a certain procedure, such that when the procedure is repeatedly applied to a series of hypothetical datasets drawn from the studied population/populations, it yields intervals that contain the true parameter value (in our example, it means the true difference between the two groups) in 95% of the cases. For the effect estimate and confidence intervals to be valid, the data and test must meet the assumptions of the estimating procedure. In colloquial terms, if we conduct this research over and over (repeating the same sampling procedure, administering the same experimental manipulation, conducting the same statistical analysis, etc.), because of sampling variability (our samples are slightly different at each time), we will get different Cohen‚Äôs values. For each of these values, we calculate a 95% interval. Then, among all these many intervals, we expect that 95% of them will contain the true, which we never know exactly.¬´\n\nDiese Interpretation wird sehr gut durch diese interaktive Visualisierung  veranschaulicht.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Konfidenzintervalle</span>"
    ]
  },
  {
    "objectID": "Konfidenzintervalle.html#donts",
    "href": "Konfidenzintervalle.html#donts",
    "title": "4¬† Konfidenzintervalle",
    "section": "4.2 Don‚Äôts",
    "text": "4.2 Don‚Äôts\n\np-Werte und Konfidenzintervalle dr√ºcken dieselbe Information in unterschiedlichen Metriken aus. Da p-Werte keine Evidenz f√ºr die Nullhypothese liefern k√∂nnen, k√∂nnen CI dies auch nicht.\nDie Interpretation von CI ¬ªals das Intervall, das den wahren Wert mit 95%-Wahrscheinlichkeit enth√§lt¬´ ist falsch bzw. mindestens hochproblematisch.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Konfidenzintervalle</span>"
    ]
  },
  {
    "objectID": "Konfidenzintervalle.html#dos",
    "href": "Konfidenzintervalle.html#dos",
    "title": "4¬† Konfidenzintervalle",
    "section": "4.3 Dos",
    "text": "4.3 Dos\n\nWer frequentistische Inferenzstatistik betreibt verliert nichts und gewinnt nur, wenn zus√§tzlich zum p-Wert Ci angegeben werden. Go for it üí®.\n\n\n\n\n\nJan√©, M. B., Xiao, Q., Yeung, S. K., Ben-Shachar, M. S., Caldwell, A. R., Cousineau, D., ‚Ä¶ Feldman, G. (2024). Guide to Effect Sizes and Confidence Intervals.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Konfidenzintervalle</span>"
    ]
  },
  {
    "objectID": "Highest Density Posterior Intervals.html#interaktive-visualisierung",
    "href": "Highest Density Posterior Intervals.html#interaktive-visualisierung",
    "title": "5¬† Highest Density Posterior Intervals",
    "section": "5.1 Interaktive Visualisierung",
    "text": "5.1 Interaktive Visualisierung\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(bslib)\nui &lt;- page_fluid(\n  theme = bs_theme(\n    # Controls the default grayscale palette\n   # bg = \"#1bbc9d30\",\n   # fg = \"#B8BCC2\",\n    \"bg-dark\" = \"#1bbc9d50\",\n    # Controls the accent (e.g., hyperlink, button, etc) colors\n    primary = \"#1bbc9d\",\n    secondary = \"#1bbc9d\",\n    \"input-border-color\" = \"#1bbc9d\"\n  ),\n  h5(\"\"),\n  layout_column_wrap(\n    card(card_header(class = \"bg-dark\", \"Prior\"),\n         card_body(\n           sliderInput(\n             \"prior_mu\",\n             \"Prior Mean\",\n             min = 0,\n             max = 1,\n             value = .5,\n             step = .01\n           ),\n           sliderInput(\n             \"prior_phi\",\n             \"Prior Precision\",\n             min = 2,\n             max = 100,\n             value = 3,\n             step = 1\n           )\n         )),\n    card(card_header(class = \"bg-dark\", \"Data\"),\n         card_body(\n           numericInput(\n             \"successes\",\n             \"Zustimmung G9\",\n             min = 0,\n             value = 13,\n             step = 1\n           ),\n           numericInput(\n             \"failures\",\n             \"Ablehnung G9\",\n             min = 0,\n             value = 8,\n             step = 1\n           )\n         ))), \n  card(card_header(\"Posterior\", class = \"bg-dark\"),\n       card_body(plotOutput(\"plot\")))\n)\n\n\nserver &lt;- function(input, output, session) {\n  \n### custom functions ###########################################################\n# muphi_to_shapes \nmuphi_to_shapes &lt;- function(mu, phi) {\n  shape1 &lt;- mu * phi\n  shape2 &lt;- (1 - mu) * phi\n  return(list(shape1 = shape1, shape2 = shape2))\n}\n\n### aux variables ##############################################################\n# convert prior parameterization\n\nprior_shapes &lt;- reactive({\n  muphi_to_shapes(input$prior_mu, input$prior_phi)\n})\n\n### plot #######################################################################\noutput$plot &lt;- renderPlot({\n  \n  # set x-axis\n  p &lt;- seq(0,1, length=1000)\n  \n  # compute max-desity for ylim and legend position\n  density_max &lt;-\n    max(c(\n      dbeta(p,\n            prior_shapes()$shape1,\n            prior_shapes()$shape2),\n      dbeta(\n        p,\n        prior_shapes()$shape1 + input$successes,\n        prior_shapes()$shape2 + input$failures\n      )\n    ))\n  \n  # compute lower bound of 96%-HPDI\n  hpdi_lb &lt;-\n    qbeta(.02,\n           prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  # compute upper bound of 96%-HPDI\n  hpdi_ub &lt;-\n    qbeta(.98,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures)\n  \n  # create plot\n  plot(\n    p,\n    dbeta(p,\n          prior_shapes()$shape1,\n          prior_shapes()$shape2),\n    type = 'l',\n    col = \"#1bbc9d\",\n    ylab = \"Wahrscheinlichkeitsdichte\",\n    xlab = \"Anteil G9-Bef√ºrworter:innen\",\n    frame.plot = F,\n    ylim = c(0, density_max)\n    )\n  lines(p,\n        dbeta(\n          p,\n          prior_shapes()$shape1 + input$successes,\n          prior_shapes()$shape2 + input$failures\n          ),\n          col = '#EA80FC'\n        )\n  polygon(c(hpdi_lb, hpdi_lb, hpdi_ub, hpdi_ub),\n          c(0, density_max/40, density_max/40, 0),\n          col = \"#EA80FC30\",\n          border = \"#EA80FC00\")\n  legend(\n    bty = \"n\",\n    .8,\n    density_max,\n    c('Prior', 'Posterior', '96% HPDI'),\n    lty = c(1, 1, 1),\n    lwd = c(1, 1, 8),\n    col = c('#1bbc9d', '#EA80FC', '#EA80FC30')\n  )\n\n})\n\n### debug ######################################################################\n# output$debug &lt;- renderPrint({\n#   max(c(\n#                dbeta(p, \n#                      prior_shapes()$shape1, \n#                      prior_shapes()$shape2),\n#                dbeta(p, \n#                      prior_shapes()$shape1 + input$successes, \n#                      prior_shapes()$shape2 + input$failures))\n#              )\n#              \n# })\n\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Highest Density Posterior Intervals</span>"
    ]
  },
  {
    "objectID": "Literatur.html",
    "href": "Literatur.html",
    "title": "Literatur",
    "section": "",
    "text": "D√∂ring, N., & Bortz, J. (2016). Forschungsmethoden und\nEvaluation in den Sozial- und Humanwissenschaften (5.,\nvollst). Berlin, Heidelberg: Springer.\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und\nForschungsmethoden: Lehrbuch. Mit\nOnline-Materialien (3rd ed.). Beltz.\n\n\nGoodman, S. (2008). A dirty dozen:\nTwelve p-value misconceptions. Seminars in\nHematology, 45(3), 135‚Äì140.\n\n\nGu, X., Hoijtink, H., Mulder, J., & Rosseel, Y. (2019). Bain:\nA program for Bayesian testing of order\nconstrained hypotheses in structural equation models. Journal of\nStatistical Computation and Simulation, 89(8), 1526‚Äì1553.\n\n\nHoijtink, H. (2012). Informative hypotheses: Theory and\npractice for behavioral and social scientists. Boca\nRaton: CRC.\n\n\nJan√©, M. B., Xiao, Q., Yeung, S. K., Ben-Shachar, M. S., Caldwell, A.\nR., Cousineau, D., ‚Ä¶ Feldman, G. (2024). Guide to effect sizes and\nconfidence intervals.\n\n\nKruschke, John K. (2015). Doing Bayesian data analysis:\nA tutorial with R, JAGS, and\nStan (2nd ed.). Academic Press.\n\n\nKruschke, John K., & Liddell, T. M. (2018). The\nBayesian new statistics: Hypothesis testing,\nestimation, meta-analysis, and power analysis from a\nBayesian perspective. Psychonomic Bulletin &\nReview, 25, 178‚Äì206.\n\n\nLakens, D. (2017). Equivalence\nTests: A Practical Primer for t\nTests, Correlations, and\nMeta-Analyses. Social Psychological and Personality\nScience, 8(4), 355‚Äì362.\n\n\nRouder, J. N. (2014). Optional stopping:\nNo problem for Bayesians. Psychonomic\nBulletin & Review, 21(2), 301‚Äì308.\n\n\nWagenmakers, E.-J. (2022). Approximate objective\nBayes Factors from p-values and sample size:\nThe 3p$\\surd$n rule (Preprint).\nPsyArXiv.\n\n\nWong, T. K., Kiers, H., & Tendeiro, J. (2022). On the Potential\nMismatch Between the Function of the Bayes\nFactor and Researchers‚Äô\nExpectations. Collabra: Psychology,\n8(1), 36357.",
    "crumbs": [
      "Literatur"
    ]
  }
]